# streamlit_app_v0_4_6.py

import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import io
import nltk
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import PCA
import numpy as np
import matplotlib.pyplot as plt
from nltk.tokenize import sent_tokenize
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
from reportlab.lib.pagesizes import A4
from reportlab.lib import colors
from reportlab.lib.styles import getSampleStyleSheet

# nltk.download('punkt')
# âœ… punkt ê²½ë¡œ ìˆ˜ë™ ì§€ì •
nltk.data.path.append("./.nltk_data")

# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
def clean_text_from_url(url):
    try:
        res = requests.get(url)
        soup = BeautifulSoup(res.text, 'html.parser')
        for tag in soup(['script', 'style', 'noscript']):
            tag.decompose()
        text = soup.get_text(separator=' ', strip=True)
        return re.sub(r'\s+', ' ', text)
    except Exception as e:
        st.error(f"âŒ Failed to fetch URL:\n{e}")
        return ""

def chunk_text_by_sentence(text, chunk_size=500):
    sentences = sent_tokenize(text, language='english')
    chunks, current_chunk = [], ""
    for sentence in sentences:
        if len(current_chunk) + len(sentence) < chunk_size:
            current_chunk += " " + sentence
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk:
        chunks.append(current_chunk.strip())
    return chunks

# ---------- ì‹œê°í™” (ë‹¤í¬ëª¨ë“œìš© ê°œì„  ë²„ì „) ----------
def draw_chart(df, threshold):
    fig, ax = plt.subplots(figsize=(10, min(0.6 * len(df), 10)))
    fig.patch.set_facecolor('#0e1117')
    ax.set_facecolor('#0e1117')

    fig.suptitle(
        f"Similarity Score by Question ({df[df['status']=='Covered'].shape[0]}/{len(df)})",
        fontsize=14,
        color='white'
    )

    colors = ['#00e676' if s == 'Covered' else '#757575' for s in df['status']]
    bars = ax.barh(df["question"], df["similarity"], color=colors)

    for i, bar in enumerate(bars):
        score = df["similarity"].iloc[i]
        ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,
                f"{score:.2f}", va='center', fontsize=9, color='white')

    ax.axvline(threshold, color='red', linestyle='--', label=f'Threshold = {threshold:.2f}')
    ax.set_xlabel("Similarity Score", color='white')
    ax.set_ylabel("Question", color='white')
    ax.tick_params(axis='x', colors='white')
    ax.tick_params(axis='y', colors='white')
    ax.invert_yaxis()
    ax.legend(facecolor='#0e1117', edgecolor='white', labelcolor='white')
    st.pyplot(fig)

def draw_pie_chart(df):
    import matplotlib.pyplot as plt

    covered = df[df['status'] == 'Covered'].shape[0]
    not_covered = df[df['status'] == 'Not Covered'].shape[0]
    total = covered + not_covered

    # ìƒ‰ìƒ ë° ë ˆì´ë¸”
    labels = ['Covered', 'Not Covered']
    sizes = [covered, not_covered]
    colors = ['#00e676', '#757575']

    fig, ax = plt.subplots(figsize=(1.6, 1.6))
    fig.patch.set_facecolor('#0e1117')  # ë‹¤í¬ëª¨ë“œ ë°°ê²½
    ax.set_facecolor('#0e1117')

    wedges, texts = ax.pie(
        sizes,
        labels=labels,
        colors=colors,
        startangle=90,
        wedgeprops=dict(width=0.45, edgecolor='white'),
        textprops=dict(color='white', fontsize=4)
    )

    # ì¤‘ì•™ í…ìŠ¤íŠ¸ ì¶”ê°€
    ax.text(0, 0, f"{covered}/{total}\nCovered", color='white',
            ha='center', va='center', fontsize=4, fontweight='bold')

    ax.axis('equal')  # ì›í˜• ìœ ì§€
    st.pyplot(fig)


# ---------- PDF ----------
def generate_pdf(df, model_name, threshold):
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    styles = getSampleStyleSheet()
    elements = []

    elements.append(Paragraph("Embedding Relevance Score Report", styles['Title']))
    elements.append(Spacer(1, 12))
    summary = f"Model: {model_name} | Threshold: {threshold:.2f} | Coverage: {df[df['status'] == 'Covered'].shape[0]}/{df.shape[0]}"
    elements.append(Paragraph(summary, styles['Normal']))
    elements.append(Spacer(1, 12))

    data = [["#", "Question", "Similarity", "Status", "Top Matched Chunk"]]
    for i, row in df.iterrows():
        data.append([
            f"Q{i+1}",
            row["question"],
            f"{row['similarity']:.4f}",
            row["status"],
            row["matched_chunk"][:100] + "..."
        ])

    table = Table(data, colWidths=[30, 150, 60, 60, 200])
    table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#4F81BD")),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 10),
        ('FONTSIZE', (0, 1), (-1, -1), 8),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('VALIGN', (0, 0), (-1, -1), 'TOP'),
        ('GRID', (0, 0), (-1, -1), 0.25, colors.gray),
        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.whitesmoke, colors.lightgrey])
    ]))

    elements.append(table)
    doc.build(elements)
    buffer.seek(0)
    return buffer

# ---------- í•˜ì´ë¼ì´íŒ… ----------
def highlight_chunk(chunk, question):
    words = [w.strip('.,!?') for w in question.lower().split()]
    for w in sorted(set(words), key=len, reverse=True):
        if len(w) > 2:
            chunk = re.sub(
                r"\b({})\b".format(re.escape(w)),
                r"<mark>\1</mark>",
                chunk,
                flags=re.IGNORECASE
            )
    return chunk

# ---------- Streamlit UI ----------
st.set_page_config(page_title="Embedding Relevance Score Analyzer", layout="wide")
st.title("ğŸ” Embedding Relevance Score Analyzer v0.5")

# âœ… ë‹¤í¬ëª¨ë“œ ëŒ€ì‘ í•˜ì´ë¼ì´íŒ… ìŠ¤íƒ€ì¼
st.markdown("""
<style>
html, body, mark {
    background-color: #FFD54F !important;
    color: black !important;
    padding: 0 2px;
    border-radius: 2px;
}
[data-testid="stMarkdownContainer"] mark {
    background-color: #FFD54F !important;
    color: black !important;
}
</style>
""", unsafe_allow_html=True)

model_options = {
    "all-MiniLM-L6-v2": "Fast & lightweight",
    "all-mpnet-base-v2": "High accuracy",
    "BAAI/bge-base-en-v1.5": "Strong semantic understanding",
    "paraphrase-MiniLM-L6-v2": "Optimized for paraphrase",
    "all-distilroberta-v1": "RoBERTa-based"
}

# Sidebar
with st.sidebar:
    model_name = st.selectbox(
    label="ğŸ”¬ Select Model",
    options=list(model_options.keys()),
    help="â„¹ï¸ ëª¨ë¸ë³„ ì†ë„, ì •í™•ë„, íŠ¹ì„±ì€ ì•„ë˜ 'ğŸ“˜ ëª¨ë¸ ì„¤ëª… ë³´ê¸°'ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

    with st.expander("ğŸ“˜ ëª¨ë¸ ì„¤ëª… ë³´ê¸°"):
        st.markdown("""
    <div style='font-size:10.5px'>
        
    | ëª¨ë¸ëª… | íŠ¹ì§• | ì†ë„ | ì •í™•ë„ | ì í•©í•œ ìš©ë„ |
    |--------|------|------|--------|--------------|
    | **all-MiniLM-L6-v2** | (Default) ë¹ ë¥´ê³  ê°€ë³ê³  ë¬´ë‚œ | ğŸŸ¢ ë§¤ìš° ë¹ ë¦„ | âšª ì¤‘ê°„ | ì‹¤ì‹œê°„ ë¶„ì„ |
    | **all-mpnet-base-v2** | ë†’ì€ ì •í™•ë„ | ğŸ”¶ ëŠë¦¼ | ğŸŸ¢ ë§¤ìš° ë†’ìŒ | í’ˆì§ˆ ìœ„ì£¼ ë¶„ì„ |
    | **BAAI/bge-base-en-v1.5** | GenAI ê²€ìƒ‰ ìµœì í™” | ğŸŸ¡ ë³´í†µ | ğŸŸ¢ ë†’ìŒ | GPT/RAG ê²€ìƒ‰ |
    | **paraphrase-MiniLM-L6-v2** | íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆ íŠ¹í™” | ğŸŸ¢ ë¹ ë¦„ | âšª ì¤‘ê°„ | ì˜ë¯¸ ìœ ì‚¬ì„± íŒŒì•… |
    | **all-distilroberta-v1** | RoBERTa ê¸°ë°˜ | ğŸŸ¡ ë³´í†µ | âšª ì¤‘ê°„ | RoBERTa ê²°ê³¼ ë¹„êµ |

    </div>
    """, unsafe_allow_html=True)


    threshold = st.slider("ğŸ“Š Similarity Threshold", 0.6, 0.9, 0.75, step=0.01)
    chunk_size = st.slider("ğŸ§© Chunk Size", 300, 1000, 500, step=100)
    top_n = st.slider("ğŸ” Top N Chunks", 1, 5, 3)

# Main inputs
st.header("Step 1: Enter Questions")
questions_input = st.text_area("One question per line", height=200)

st.header("Step 2: Enter Target URL")
url = st.text_input("Enter target URL")

if st.button("ğŸš€ Run Analysis"):
    if not questions_input or not url:
        st.warning("Please provide both questions and a URL.")
    else:
        with st.spinner("Running analysis..."):
            questions = [q.strip() for q in questions_input.strip().split('\n') if q.strip()]
            model = SentenceTransformer(model_name)
            full_text = clean_text_from_url(url)
            chunks = chunk_text_by_sentence(full_text, chunk_size=chunk_size)

            chunk_vectors = model.encode(chunks)
            question_vectors = model.encode(questions)
            similarity_matrix = cosine_similarity(question_vectors, chunk_vectors)

            results = []
            for i, q in enumerate(questions):
                top_indices = similarity_matrix[i].argsort()[::-1][:top_n]
                top_scores = similarity_matrix[i][top_indices]
                top_chunks = [chunks[idx] for idx in top_indices]

                top_match_text = ""
                for rank, (score, chunk) in enumerate(zip(top_scores, top_chunks), 1):
                    top_match_text += f"ğŸ”¹ Top {rank} (score={score:.4f})\n{chunk[:300]}...\n\n"

                status = 'Covered' if top_scores[0] >= threshold else 'Not Covered'
                results.append({
                    "question": q,
                    "similarity": round(float(top_scores[0]), 4),
                    "status": status,
                    "matched_chunk": top_match_text.strip()
                })

            df_result = pd.DataFrame(results)

        st.success("âœ… Analysis Complete")

        # í‘œ
        st.subheader("ğŸ” Top Matched Chunks")
        st.dataframe(df_result[["question", "similarity", "status", "matched_chunk"]], use_container_width=True)

        # ì‹œê°í™”
        st.subheader("ğŸ“Š Coverage Visualization")
        draw_chart(df_result, threshold)
        draw_pie_chart(df_result)

                # ì‹œê°í™”: ë§‰ëŒ€ + íŒŒì´ì°¨íŠ¸ + PCA
        def draw_chart(df, threshold):
            fig, ax = plt.subplots(figsize=(10, min(0.6 * len(df), 10)))
            fig.patch.set_facecolor('#0e1117')
            ax.set_facecolor('#0e1117')
            fig.suptitle(f"Similarity Score by Question ({df[df['status']=='Covered'].shape[0]}/{len(df)})", fontsize=14, color='white')
            colors = ['#00e676' if s == 'Covered' else '#757575' for s in df['status']]
            bars = ax.barh(df["question"], df["similarity"], color=colors)
            for i, bar in enumerate(bars):
                score = df["similarity"].iloc[i]
                ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2, f"{score:.2f}", va='center', fontsize=9, color='white')
            ax.axvline(threshold, color='red', linestyle='--', label=f'Threshold = {threshold:.2f}')
            ax.set_xlabel("Similarity Score", color='white')
            ax.set_ylabel("Question", color='white')
            ax.tick_params(axis='x', colors='white')
            ax.tick_params(axis='y', colors='white')
            ax.invert_yaxis()
            ax.legend(facecolor='#0e1117', edgecolor='white', labelcolor='white')
            st.pyplot(fig)

        def draw_pie_chart(df):
            covered = df[df['status'] == 'Covered'].shape[0]
            not_covered = df[df['status'] == 'Not Covered'].shape[0]
            fig, ax = plt.subplots(figsize=(1.6, 1.6))
            fig.patch.set_facecolor('#0e1117')
            ax.set_facecolor('#0e1117')
            wedges, texts = ax.pie([covered, not_covered], labels=['Covered', 'Not Covered'],
                                colors=['#00e676', '#757575'], startangle=90,
                                wedgeprops=dict(width=0.45, edgecolor='white'),
                                textprops=dict(color='white', fontsize=4))
            ax.text(0, 0, f"{covered}/{covered + not_covered}\nCovered", color='white', ha='center', va='center', fontsize=4, fontweight='bold')
            ax.axis('equal')
            st.pyplot(fig)

        def draw_pca_plot(question_vectors, matched_chunk_vectors):
            pca = PCA(n_components=2)
            all_vectors = np.vstack([question_vectors, matched_chunk_vectors])
            reduced = pca.fit_transform(all_vectors)
            question_points = reduced[:len(question_vectors)]
            chunk_points = reduced[len(question_vectors):]
            fig, ax = plt.subplots(figsize=(10, 6))
            fig.patch.set_facecolor('#0e1117')
            ax.set_facecolor('#0e1117')
            ax.grid(True, color='#444444', linestyle='--', linewidth=0.5)  # ğŸ‘ˆ íšŒìƒ‰ ì ì„ ìœ¼ë¡œ ê·¸ë¦¬ë“œ ì¶”ê°€
            ax.set_title("Question & Answer Embeddings in 2D Space (PCA Reduced)", color='white')
            ax.scatter(question_points[:, 0], question_points[:, 1], color='deepskyblue', label='Question')
            ax.scatter(chunk_points[:, 0], chunk_points[:, 1], color='limegreen', label='Answer Chunk')
            for i in range(len(question_points)):
                ax.text(question_points[i, 0], question_points[i, 1], f"Q{i+1}", color='white', fontsize=9)
                ax.text(chunk_points[i, 0], chunk_points[i, 1], f"A{i+1}", color='white', fontsize=9)
            ax.set_xlabel("PCA Component 1", color='white')
            ax.set_ylabel("PCA Component 2", color='white')
            ax.tick_params(colors='white')
            ax.legend(facecolor='#0e1117', edgecolor='white', labelcolor='white')
            st.pyplot(fig)

        # ğŸ” Top 1 ì²­í¬ë§Œ ì¶”ì¶œ (ì •ê·œì‹ ê¸°ë°˜)
        top1_chunks = []

        for row in df_result.itertuples():
            match = re.search(r"ğŸ”¹ Top 1 \(score=.*?\)\n(.+?)(?=\nğŸ”¹ Top|\Z)", row.matched_chunk, re.DOTALL)
            if match:
                top1_chunks.append(match.group(1).strip())
            else:
                top1_chunks.append("")

        # âœ… Top 1 ì²­í¬ ì„ë² ë”©
        matched_chunk_vectors = model.encode(top1_chunks)

        # ğŸ¯ PCA ì‹œê°í™”
        draw_pca_plot(question_vectors, matched_chunk_vectors)

        # ğŸ“‹ ì°¨íŠ¸ í•˜ë‹¨ Q/A ìš”ì•½ í…Œì´ë¸”
        pca_table_data = []
        for i, row in df_result.iterrows():
            pca_table_data.append({
                "Q Label": f"Q{i+1}",
                "Q Text": row["question"],
                "A Label": f"A{i+1}",
                "A Text": top1_chunks[i]
            })

        df_pca_table = pd.DataFrame(pca_table_data)
        st.subheader("ğŸ“‹ Label Reference Table")
        st.dataframe(df_pca_table, use_container_width=True)


        # PCA ë¼ë²¨-ë‚´ìš© ë§¤í•‘ í…Œì´ë¸” í‘œì‹œ
        pca_mapping = pd.DataFrame({
            "Label": [f"Q{i+1}" for i in range(len(questions))] + [f"A{i+1}" for i in range(len(questions))],
            "Type": ["Question"] * len(questions) + ["Answer Chunk"] * len(questions),
            "Text": questions + [row.matched_chunk[:100] + "..." for row in df_result.itertuples()]
        })

        # Highlighted Chunk Preview
        st.subheader("ğŸ’¬ Highlighted Chunk Preview")
        for i, row in df_result.iterrows():
            st.markdown(f"**Q{i+1}: {row['question']}**", unsafe_allow_html=True)

            # ì ìˆ˜ ê°•ì¡°: score=0.78xx ë¶€ë¶„ë§Œ ìƒ‰ìƒ ì²˜ë¦¬
            # row["matched_chunk"]ëŠ” multiline stringì´ë¯€ë¡œ ì •ê·œì‹ìœ¼ë¡œ ì¹˜í™˜
            highlighted_text = highlight_chunk(row["matched_chunk"], row["question"])
            highlighted_text = re.sub(
                r"(score=)(\d\.\d+)",
                r"<span style='color:#FF4B4B; font-weight:bold;'>\1\2</span>",
                highlighted_text
            )

            st.markdown(
                f"<div style='background:#0e1117; padding:10px; border-radius:5px; font-size:14px'>{highlighted_text}</div>",
                unsafe_allow_html=True
            )
            st.markdown("---")

        # Export Results ì„¹ì…˜ ë‚´ ë²„íŠ¼ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í„°ë§ˆì´ì§• ì¶”ê°€
        st.subheader("ğŸ“¥ Export Results")

        # CSVì™€ PDF ë²„í¼ ìƒì„±
        csv_buffer = io.StringIO()
        df_result.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        pdf_buffer = generate_pdf(df_result, model_name, threshold)

        # âœ… CSS ì¶”ê°€: ë²„íŠ¼ì„ ì¢Œì¸¡ ì •ë ¬ë¡œ ë‚˜ë€íˆ, ìŠ¤íƒ€ì¼ í†µì¼
        st.markdown("""
            <style>
            .button-row {
                display: flex;
                justify-content: flex-start;
                gap: 10px;
                margin-bottom: 1rem;
            }
            .button-row .stButton > button {
                background-color: #1f77b4;
                color: white;
                padding: 0.4em 1.2em;
                border-radius: 6px;
                border: none;
                font-size: 0.9em;
            }
            </style>
        """, unsafe_allow_html=True)

             # âœ… ë²„íŠ¼ ë‚˜ë€íˆ ë°°ì¹˜
        st.markdown('<div class="button-row">', unsafe_allow_html=True)
        col1, col2 = st.columns([1, 1])
        with col1:
            st.download_button("Download CSV", csv_buffer.getvalue(), "embedding_analysis_results.csv", "text/csv", key="csv_dl")
        with col2:
            st.download_button("Download PDF", pdf_buffer, "embedding_analysis_results.pdf", "application/pdf", key="pdf_dl")
        st.markdown('</div>', unsafe_allow_html=True)
